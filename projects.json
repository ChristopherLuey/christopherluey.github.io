{
  "projects": [
    {
      "title": "Lagrangian Dynamics Simulation",
      "description": "A simulation of a gymnastics high bar dismount using Lagrangian dynamics and numerical methods.<br><br><span class=\"class-with\">Class with Prof. Todd Murphey (Northwestern University)</span>",
      "media": ["images/1/0726.mov"], 
      "link": "project.html?title=Lagrangian%20Dynamics%20Simulation",
      "details": {
        "pageTitle": "Lagrangian Dynamics Simulation",
        "projectDescription": "Lagrangian dynamics simulation<br><br><span class=\"class-with\">Class with Prof. Todd Murphey (Northwestern University)</span>",
        "detailedDescription": "<p>This project involves simulating a gymnastics high bar dismount solving the Euler-Lagrange Equations and using numerical simulation techniques. The system is modeled with two rigid bodies representing the human arms and torso, each with defined volume and mass.</p><p>The simulation is divided into two phases:</p><ul><li><strong>Phase One (Double Pendulum):</strong> The simulation begins with the bodies in a vertically upright position and initial angular velocities. The arms (Body B) rotate around the high bar (2.8m high) until a specified release angle is reached. This phase employs the Euler-Lagrange equation to model the dynamics and constraints using variational calculus to derive the equations of motion.</li><li><strong>Phase Two (Projectile Motion):</strong> Upon reaching the release angle, the constraint on the arms is removed, and both bodies follow a projectile trajectory. The simulation continues until a plastic impact is detected when the torso (Body D) hits the ground. The impact is considered successful when both corners of the torso contact the ground simultaneously.</li></ul><p>The simulation leverages numerical methods, including symbolic computation SymPy for the Euler-Lagrange equations and numerical solvers for the projectile motion phase, to ensure accurate and realistic modeling of the dismount. Transformations between different reference frames are handled using rotational matrices to account for the orientation and position of the rigid bodies. Variational calculus is applied to derive the governing equations from the Lagrangian, which is the difference between kinetic and potential energy of the system.</p>",
        "media": ["images/1/IMG_0410_Original.jpeg", "images/1/0726.mov", "images/1/1.mov", "images/1/IMG_0415_Original.jpeg", "images/1/IMG_0413_Original.jpeg"]
      }
    },
    {
      "title": "Pick and Place Robotic Manipulation",
      "description": "End-effector trajectory planning, odometry, inverse kinematics.<br><br><span class=\"class-with\">Class with Prof. Kevin Lynch (Northwestern University)</span>",
      "media": ["images/2/0725.mov"],
      "link": "project.html?title=Pick%20and%20Place%20Robotic%20Manipulation",
      "details": {
        "pageTitle": "Pick and Place Robotic Manipulation",
        "projectDescription": "End-effector trajectory planning, odometry, inverse kinematics.<br><br><span class=\"class-with\">Class with Prof. Kevin Lynch (Northwestern University)</span>",
        "detailedDescription": "<p>This project focused on developing a sophisticated controller for the youBot mobile manipulator, equipped with a 5R joint arm and 4 mecanum wheels. The goal was to enable precise pick and place operations for a cube between specified configurations.</p><p><strong>Odometry:</strong> Accurate position estimation using sensor data and kinematic equations, essential for the manipulator's precise movements.</p><p><strong>Feedback Control:</strong> Implementation of Proportional-Integral (PI) controllers to ensure the end-effector accurately follows the planned trajectory. The PI controller adjusts the manipulator's movements based on both the current error (proportional term) and the accumulated error over time (integral term).</p><p><strong>Trajectory Generation:</strong> Creation of smooth and feasible paths using polynomial and spline interpolation, and SE(3) transformations to manage the full pose of the end-effector in 3D space.</p><p>The project progressed through milestones:</p><ul><li><strong>Milestone 1:</strong> Developed the NextStep function for basic control logic and motion commands.</li><li><strong>Milestone 2:</strong> Designed the TrajectoryGeneration function to generate optimal paths, employing SE(3) matrices.</li><li><strong>Milestone 3:</strong> Integrated the PI controller within the FeedbackControl function to reduce trajectory tracking errors.</li></ul><p>Three PI controller configurations were tested:</p><ul><li><strong>Best Configuration:</strong> Feedforward plus P controller with gains Kp = 0.4 per second, Ki = 0. Minimal tracking error.</li><li><strong>Overshoot Configuration:</strong> Feedforward plus PI controller with gains Kp = 0.6 per second, Ki = 0.4 per second squared. Initial overshoot and oscillations before stabilization.</li><li><strong>New Task Configuration:</strong> Feedforward plus PI controller for new positions with gains Kp = 2.0 per second, Ki = 0.05 per second squared. High precision in operations.</li></ul><p>The PI controller was implemented in Python using NumPy for numerical computations. Key aspects included:</p><ul><li><strong>Proportional Term (P):</strong> Adjusts control input proportionally to current error.</li><li><strong>Integral Term (I):</strong> Accumulates error over time, addressing biases and ensuring long-term accuracy.</li><li><strong>Feedback Loop:</strong> Continuously monitors end-effector's position and orientation, updating control inputs in real-time to minimize errors.</li></ul><p>Advanced techniques included Jacobian singularity avoidance to prevent high joint velocities and ensure smooth motion. This project demonstrated advanced control theory, robotic kinematics, numerical methods, and Python programming for robotic applications, emphasizing the importance of precise tuning and control strategy adaptation.</p>",
        "media": ["images/2/0725.mov", "images/2/Milestone2.mov", "images/2/overshoot_simulation.mp4", "images/2/part3a.mov"]
      }
    },
    {
      "title": "6D Object Pose Estimation",
      "description": "Using RGB video to estimate YCB object poses for tele-operated robot.<br><br><span class=\"class-with\">Research with Prof. Ed Colgate (Northwestern University)</span>",
      "media": ["images/3/3.mov"],
      "link": "project.html?title=6D%20Object%20Pose%20Estimation",
      "details": {
        "pageTitle": "6D Object Pose Estimation",
        "projectDescription": "Using RGB video to estimate YCB object poses for tele-operated robot.<br><br><span class=\"class-with\">Research with Prof. Ed Colgate (Northwestern University)</span>",
        "detailedDescription": "<p>This project focuses on 6D object pose estimation, which involves determining the SE(3) transformation that maps an object's body frame to the camera frame using RGB and RGBD images. This technique is crucial for applications in robotics, augmented reality, and autonomous driving.</p><p>The process of 6D pose estimation includes:</p><ul><li><strong>Bounding Box Object Detection:</strong> Identifying objects in the scene using bounding boxes.</li><li><strong>Deep Neural Network Processing:</strong> Using neural networks to process the bounding box information and estimate the 6D pose.</li></ul><p>The project explored several methodologies:</p><ul><li><strong>Template-Based Methods:</strong> Utilized predefined models to match against observed data. Effective for objects with unique shapes but struggled with occlusions and required a large number of templates.</li><li><strong>Point-Based Methods:</strong> Focused on matching specific geometric points. Suitable for rigid objects but sensitive to noise and required distinct points for matching.</li><li><strong>Local Descriptor-Based Methods:</strong> Described local areas around key points using descriptors. Robust to lighting changes and occlusions but computationally intensive.</li><li><strong>Feature-Based Methods:</strong> Used distinctive features like edges and corners for matching. Effective in various conditions but struggled with low-texture objects and occlusions.</li></ul><p>The project also involved advanced deep learning techniques:</p><ul><li><strong>PoseCNN:</strong> Classified 3D rotation and translation separately using semantic labels and CAD models.</li><li><strong>DeepIM:</strong> Predicted optical flow to aid pose estimation and used auxiliary branches for optical flow and mask prediction.</li><li><strong>DenseFusion:</strong> Combined RGB and depth data at the pixel level for accurate pose prediction.</li></ul><p>Challenges addressed included dealing with occlusions, varying lighting conditions, and the need for extensive training data. The project also explored integration of depth sensing technologies to enhance pose estimation accuracy.</p><p>Skills learned and applied:</p><ul><li>Advanced computer vision techniques.</li><li>Deep learning algorithms for object detection and pose estimation.</li><li>Handling RGB and RGBD data for real-time applications.</li><li>Development and implementation of neural network models.</li></ul><p>This research significantly advanced the understanding and application of 6D object pose estimation, providing robust solutions for real-world applications in robotics and beyond.</p>",
        "media": ["images/3/3.mov"]
      }
    },
    {
      "title": "Online Robotic Gait Control using Generative AI",
      "description": "Using an autoencoder to learn and generate control sequences for robot walking.<br><br><span class=\"class-with\">Research with Prof. Todd Murphey (Northwestern University)</span>",
      "media": ["images/4/4.mov"],
      "link": "project.html?title=Online%20Robotic%20Gait%20Control%20using%20Generative%20AI",
      "details": {
        "pageTitle": "Research: Online Robotic Gait Control using Generative AI",
        "projectDescription": "Using an autoencoder to learn and generate control sequences for robot walking.<br><br><span class=\"class-with\">Research with Prof. Todd Murphey (Northwestern University)</span>",
        "detailedDescription": "<p>This project introduces a novel generative autoencoder framework for online robotic gait learning. The method utilizes a conditional variational autoencoder (CVAE) to generate structured control signals in unknown environments with unfamiliar robot dynamics. The approach incorporates a closed-loop feedback pipeline that learns from active robot ambulation and online control generation.</p><p>The pipeline consists of three stages:</p><ul><li><strong>Sampling:</strong> The encoder, decoder, and reward functions are sampled to characterize minimal loss regions, identifying promising gait descriptors for further investigation.</li><li><strong>Execution:</strong> The robot executes a selected minimal loss control signal in its environment, and its reward function is characterized.</li><li><strong>Training:</strong> The reward function and reconstructed outputs are backpropagated for weight training.</li></ul><p>The project was implemented using PyTorch for neural network development and CUDA for GPU acceleration, enabling efficient training and inference. The Mujoco Ant simulation was used for initial testing, showing that good gaits are well-represented in the latent space with minimal reconstruction loss.</p><p>The CVAE training was constrained to gaits achieving specific rewards (0.35 < x < 0.4 [m] and -0.1 < y < 0.1 [m]), and the model learned general latent features for these gaits. The framework also integrated:</p><ul><li><strong>Latent Space Analysis:</strong> Analyzing latent representations of good gait descriptors for skill-based learning.</li><li><strong>Policy Optimization:</strong> Using an optimizer and policy Ï€ loss function to refine control signals.</li><li><strong>Noise and Variational Uncertainty:</strong> Incorporating noise and uncertainty in the latent space for robust learning.</li></ul><p>Future work includes integrating this online learning approach with a physical robot and refining the latent space reward functions for more targeted learning.</p><p>Skills learned and applied in this project include:</p><ul><li>Advanced deep learning techniques using CVAE.</li><li>Implementation of neural networks using PyTorch and CUDA.</li><li>Real-time control signal generation and feedback loop design.</li><li>Simulation and validation using the Mujoco Ant environment.</li></ul><p>This research significantly advances the field of online robotic gait learning, providing robust solutions for adaptive control in dynamic environments.</p>",
        "media": ["images/4/4.mov", "images/4/4.jpeg"]
      }
    },
    {
      "title": "A Digital Twin Framework for Predictive Maintenance using Temporal Fusion Transformers",
      "description": "Using a temporal fusion transformer<br><br><span class=\"class-with\">Research with Prof. Wei Chen (Northwestern University)</span>",
      "media": ["images/5/5.jpeg"],
      "link": "project.html?title=A%20Digital%20Twin%20Framework%20for%20Predictive%20Maintenance%20using%20Temporal%20Fusion%20Transformer",
      "details": {
        "pageTitle": "Research: A Digital Twin Framework for Predictive Maintenance using Temporal Fusion Transformers",
        "projectDescription": "Using a temporal fusion transformer<br><br><span class=\"class-with\">Research with Prof. Wei Chen (Northwestern University)</span>",
        "detailedDescription": "<p>This project introduces a novel digital twin framework for predictive maintenance using Probabilistic Temporal Fusion Transformers (TFTs). The primary objective is to optimize tire resource allocation by predicting tire wear and extending the lifespan of vehicle tires, thereby reducing environmental impact and mechanical waste.</p><p>The framework integrates several advanced techniques and methods:</p><ul><li><strong>Temporal Fusion Transformer Architecture:</strong> Utilized for processing time-series data to predict future states of tires. Key components include static covariate encoders, LSTM encoder-decoder, and masked multi-head attention mechanisms.</li><li><strong>Digital Twin Method:</strong> A hybrid approach combining physical models (Finite Element Method - FEM) with machine learning models to monitor and predict the mechanical lifetime of systems.</li><li><strong>Real-Time Adaptation and Decision Making:</strong> The system employs a Tire State Decision Algorithm (TSDA) to dynamically update tire health predictions and make maintenance decisions based on real-time data.</li><li><strong>Reinforcement Learning for Resource Allocation:</strong> A reinforcement learning (RL) framework is developed to optimize tire swaps and rotations, ensuring even wear and maximizing tire life. The RL agent learns strategies from data to make optimal decisions under varying conditions.</li></ul><p>The implementation involved the following steps:</p><ol><li><strong>Data Collection:</strong> Time-series data from vehicle sensors, including tire pressure, casing temperature, load, speed, road curvature, and mileage.</li><li><strong>Data Processing:</strong> Gaussian kernel smoothing and adaptive down-sampling to handle large datasets efficiently while preserving critical features.</li><li><strong>Model Training:</strong> The TFT model was trained using PyTorch with a focus on minimizing Mean Absolute Percentage Error (MAPE). The TFT model outperformed traditional models such as LSTM, RNN, and GRU.</li><li><strong>Integration with Physical Model:</strong> The TFT model predictions are combined with FEM-based tire models to enhance prediction accuracy.</li><li><strong>Validation and Results:</strong> The model was validated using real-world data from Michelin's fleet, demonstrating accurate predictions of tire degradation and remaining mileage.</li></ol><p>The project showcased significant advancements:</p><ul><li>Improved lifetime prediction accuracy with TFT, achieving a MAPE of 29.5 compared to higher errors in other models.</li><li>Real-time decision-making capabilities for maintenance actions, reducing unnecessary tire replacements and extending tire usage.</li><li>Substantial environmental benefits by reducing CO2 emissions, energy consumption, and raw material usage.</li></ul><p>This research represents a significant step towards sustainable and efficient predictive maintenance in the automotive industry, with potential applications in various other mechanical systems.</p>",
        "media": ["images/5/5.jpeg"]
      }
    },
    {
      "title": "Image Analysis Particle Tracking",
      "description": "NDA.<br><br><span class=\"class-with\">Research with Prof. Juan Santiago (Stanford University)</span>",
      "media": ["images/6/6.JPG"],
      "link": "project.html?title=Novel%20Computer%20Vision%20Particle%20Tracking",
      "details": {
        "pageTitle": "Research: Novel Computer Vision Particle Tracking",
        "projectDescription": "NDA.<br><br><span class=\"class-with\">Research with Prof. Juan Santiago (Stanford University)</span>",
        "detailedDescription": "<p>Computer vision</p>",
        "media": ["images/6/6.JPG"]
      }
    }
  ]
}
